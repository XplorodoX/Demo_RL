<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gridworld mit Value & Policy Iteration</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body { /* ... (styles largely unchanged, minor tweaks if needed) ... */
            font-family: 'Inter', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #1f2937; min-height: 100vh; margin: 0; padding: 20px;
            display: flex; flex-direction: column; align-items: center;
        }
        .gridworld-container {
            display: flex; flex-direction: column; align-items: center;
            background: rgba(255, 255, 255, 0.97); backdrop-filter: blur(10px);
            padding: 20px; border-radius: 20px; box-shadow: 0 20px 40px rgba(0,0,0,0.2);
            width: 100%; max-width: 1000px; /* Wider for more controls */ border: 1px solid rgba(255,255,255,0.3);
        }
        .grid {
            display: grid; border: 3px solid #4f46e5; margin-bottom: 20px;
            box-shadow: 0 8px 25px rgba(79,70,229,0.3); border-radius: 12px; overflow: hidden;
        }
        .grid-cell {
            width: 65px; /* Increased size for Q-values */
            height: 65px;/* Increased size for Q-values */
            border: 1px solid #e0e0e0; display: flex; flex-direction: column;
            justify-content: center; align-items: center;
            font-size: 0.5rem; position: relative; background-color: #f8fafc;
            transition: background-color 0.3s ease, transform 0.2s ease; cursor: default;
        }
        .grid-cell.interactive-obstacle:hover { background-color: #e2e8f0; transform: scale(1.03); }
        .grid-cell.start { background: linear-gradient(135deg, #10b981, #34d399) !important; color: white; font-weight: bold; }
        .grid-cell.goal { background: linear-gradient(135deg, #f59e0b, #fbbf24) !important; color: white; font-weight: bold; }
        .grid-cell.obstacle { background: linear-gradient(135deg, #6b7280, #9ca3af) !important; color: white; }
        
        .value-text { /* V-value, centered */
            font-weight: 700; color: #1e40af; font-size: 0.8rem; /* Larger V */
            text-shadow: 0 1px 1px rgba(255,255,255,0.5);
            position: absolute; top: 50%; left: 50%;
            transform: translate(-50%, -50%);
            z-index: 5; /* Above Q-values but below arrow */
        }
        .grid-cell.start .value-text, .grid-cell.goal .value-text, .grid-cell.obstacle .value-text {
            color: white; text-shadow: 0 1px 2px rgba(0,0,0,0.3);
        }

        .policy-arrow { /* Centered, on top */
            font-size: 1.5rem; color: #c00303;
            position: absolute; top: 50%; left: 50%;
            transform: translate(-50%, -50%);
            font-weight: bold; text-shadow: 0 1px 2px rgba(0,0,0,0.2);
            z-index: 10; /* On top */
        }
        .q-values-container { position: absolute; width: 100%; height: 100%; top:0; left:0; font-size: 0.55rem; }
        .q-value { position: absolute; padding: 1px 2px; background: rgba(255,255,255,0.6); border-radius: 2px; color: #333; }
        .q-up    { top: 1px; left: 50%; transform: translateX(-50%); }
        .q-down  { bottom: 1px; left: 50%; transform: translateX(-50%); }
        .q-left  { left: 1px; top: 50%; transform: translateY(-50%); }
        .q-right { right: 1px; top: 50%; transform: translateY(-50%); }
        .grid-cell.obstacle .q-values-container, .grid-cell.goal .q-values-container, .grid-cell.start .q-values-container { display: none; }


        .agent { /* ... (largely unchanged) ... */
            width: 20px; height: 20px; background: radial-gradient(circle, #ef4444, #dc2626);
            border-radius: 50%; position: absolute; transition: transform 0.3s;
            z-index: 20; border: 2px solid white; box-shadow: 0 2px 8px rgba(220,38,38,0.4);
        }
        .panel-section { /* ... (largely unchanged) ... */
            width: 100%; padding: 15px; margin-bottom: 15px; background: rgba(236,239,241,0.7);
            border-radius: 10px; border: 1px solid rgba(79,70,229,0.1);
        }
        .panel-title { /* ... (largely unchanged) ... */
            font-size: 1rem; font-weight: 600; color: #4f46e5; margin-bottom: 10px;
            padding-bottom: 5px; border-bottom: 1px solid rgba(79,70,229,0.2);
        }
        .config-panel-grid { /* ... (largely unchanged) ... */
             display: grid; grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
             gap: 12px; align-items: end;
        }
        .controls { /* ... (largely unchanged) ... */
            display: flex; flex-wrap: wrap; gap: 10px; margin-bottom: 10px;
            justify-content: center; align-items: center;
        }
        .config-group { /* ... (largely unchanged) ... */
            display: flex; flex-direction: column; gap: 4px; min-width: 120px;
        }
        .config-group label { font-size: 0.8rem; font-weight: 500; color: #374151; }
        .config-group input, .config-group textarea, .config-group select {
            padding: 7px 9px; border-radius: 6px; border: 1px solid #d1d5db;
            background-color: white; color: #374151; font-size: 0.8rem; width: 100%; box-sizing: border-box;
        }
        .config-group textarea { min-height: 60px; font-family: monospace; }

        .controls button, .panel-section button { /* ... (largely unchanged) ... */
            padding: 9px 16px; border-radius: 8px; border: none;
            background: linear-gradient(135deg, #4f46e5, #7c3aed); color: white;
            font-weight: 600; cursor: pointer; transition: all 0.3s ease;
            font-size: 0.8rem; box-shadow: 0 3px 10px rgba(79,70,229,0.25);
        }
        .controls button:hover:not(:disabled), .panel-section button:hover:not(:disabled) { transform: translateY(-2px); box-shadow: 0 6px 15px rgba(79,70,229,0.35); }
        .controls button:disabled, .panel-section button:disabled { background: #9ca3af; cursor: not-allowed; }
        
        .parameter-group, .algo-group { /* ... (largely unchanged) ... */
            display: flex; align-items: center; gap: 8px; background: rgba(224,224,224,0.2);
            padding: 8px 12px; border-radius: 8px;
        }
        #status-message { /* ... (largely unchanged) ... */
            margin-top: 15px; font-weight: 600; color: #4f46e5; min-height: 25px; text-align: center;
            padding: 10px 20px; background: rgba(79,70,229,0.05); border-radius: 10px;
            border-left: 4px solid #4f46e5; width: 100%; box-sizing: border-box;
        }
        h1 { color: #4f46e5; margin-bottom: 15px; font-size: 1.8rem; text-align: center; }
        .stats-panel { /* ... (largely unchanged) ... */
            display: grid; grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
            gap: 10px; width: 100%; margin-bottom: 15px;
        }
        .stat-card { background: rgba(224,224,224,0.2); padding: 10px; border-radius: 8px; }
        .stat-value { font-size: 1.2rem; color: #4f46e5; }
        .stat-label { font-size: 0.7rem; color: #525252;}
        .legend { margin-bottom: 10px; }
        .legend-item { font-size: 0.75rem; }
        .legend-color { width: 16px; height: 16px; }
    </style>
</head>
<body>
    <div class="gridworld-container">
        <h1>Gridworld Explorer: Value & Policy Iteration</h1>

        <div class="panel-section">
            <div class="panel-title">Grid & Umgebungs-Konfiguration</div>
            <div class="config-panel-grid">
                <div class="config-group">
                    <label for="scenario-select">Szenarien:</label>
                    <select id="scenario-select" name="scenario-select"></select>
                </div>
                 <div class="config-group">
                    <label for="config-rows">Zeilen:</label>
                    <input type="number" id="config-rows" name="config-rows" min="2" max="15" value="5">
                </div>
                <div class="config-group">
                    <label for="config-cols">Spalten:</label>
                    <input type="number" id="config-cols" name="config-cols" min="2" max="15" value="6">
                </div>
                <div class="config-group">
                    <label for="config-start">Start (Z,S):</label>
                    <input type="text" id="config-start" name="start-state">
                </div>
                <div class="config-group">
                    <label for="config-goal">Ziel (Z,S):</label>
                    <input type="text" id="config-goal" name="goal-state">
                </div>
                <div class="config-group">
                    <label for="stochastic-env">Stochastisch:</label>
                    <select id="stochastic-env">
                        <option value="0">Nein (Deterministisch)</option>
                        <option value="1">Ja (Probabilistisch)</option>
                    </select>
                </div>
                <div class="config-group">
                    <label for="prob-intended">P(Beabsichtigt):</label>
                    <input type="number" id="prob-intended" value="0.8" min="0" max="1" step="0.05">
                </div>
                 <div class="config-group">
                    <label for="prob-slip">P(Ausrutscher):</label>
                    <input type="number" id="prob-slip" value="0.1" min="0" max="0.5" step="0.05" title="Pro Seite (links/rechts)">
                </div>
                <div class="config-group" style="grid-column: span 3;">
                    <label for="config-obstacles">Hindernisse (Z,S pro Zeile):</label>
                    <textarea id="config-obstacles" name="obstacles"></textarea>
                </div>
            </div>
             <div style="text-align: center; margin-top: 15px;">
                <button id="apply-config">‚öôÔ∏è Konfig anwenden & Reset</button>
            </div>
        </div>
        
        <div class="legend">
            <div class="legend-item"><div class="legend-color" style="background: linear-gradient(135deg, #10b981, #34d399);"></div><span>Start</span></div>
            <div class="legend-item"><div class="legend-color" style="background: linear-gradient(135deg, #f59e0b, #fbbf24);"></div><span>Ziel</span></div>
            <div class="legend-item"><div class="legend-color" style="background: linear-gradient(135deg, #6b7280, #9ca3af);"></div><span>Hindernis</span></div>
            <div class="legend-item"><div class="legend-color" style="background: radial-gradient(circle, #ef4444, #dc2626);"></div><span>Agent</span></div>
            <div class="legend-item"><div style="width:16px; height:16px; background-color: #edf2fb; border:1px solid #ccc;"></div><span>Niedriger V-Wert</span></div>
            <div class="legend-item"><div style="width:16px; height:16px; background-color: #65a30d; border:1px solid #ccc;"></div><span>Hoher V-Wert</span></div>
        </div>

        <div class="stats-panel">
            <div class="stat-card"><div class="stat-value" id="algorithm-name">Value Iteration</div><div class="stat-label">Algorithmus</div></div>
            <div class="stat-card"><div class="stat-value" id="iteration-count">0</div><div class="stat-label">Iterationen</div></div>
            <div class="stat-card"><div class="stat-value" id="delta-value">0.000</div><div class="stat-label">Delta (V) / Policy stabil</div></div>
            <div class="stat-card"><div class="stat-value" id="step-count">0</div><div class="stat-label">Agent Schritte</div></div>
        </div>

        <div class="controls">
            <div class="algo-group">
                <label for="algorithm-select">Algorithmus w√§hlen:</label>
                <select id="algorithm-select">
                    <option value="valueIteration" selected>Value Iteration</option>
                    <option value="policyIteration">Policy Iteration</option>
                    <option value="qLearning">Q-Learning</option>
                </select>
            </div>
            <button id="start-algorithm">üöÄ Algorithmus starten</button>
            <button id="animate-agent" disabled>ü§ñ Agent animieren</button>
            <button id="reset-grid">üîÑ Aktuelles Grid zur√ºcksetzen</button>
            <div class="parameter-group">
                <label for="gamma-input">Gamma (Œ≥):</label>
                <input type="number" id="gamma-input" value="0.9" min="0" max="1" step="0.05">
            </div>
            <div class="parameter-group">
                <label for="speed-input">Visual. Geschw.:</label>
                <select id="speed-input">
                    <option value="1000">Langsam</option>
                    <option value="500" selected>Normal</option>
                    <option value="200">Schnell</option>
                    <option value="50">Sehr Schnell</option>
                    <option value="10">Blitz</option>
                </select>
            </div>
            <div class="parameter-group">
                <label for="alpha-input">Alpha:</label>
                <input type="number" id="alpha-input" value="0.5" min="0" max="1" step="0.05">
            </div>
            <div class="parameter-group">
                <label for="epsilon-input">Epsilon:</label>
                <input type="number" id="epsilon-input" value="0.1" min="0" max="1" step="0.05">
            </div>
            <div class="parameter-group">
                <label for="episodes-input">Episoden:</label>
                <input type="number" id="episodes-input" value="50" min="1" max="1000">
            </div>
        </div>

        <div id="grid-container" class="grid"></div>
        <div id="status-message">Standardkonfiguration geladen.</div>
    </div>

    <script>
        // --- CONFIGURATION & CONSTANTS ---
        let GRID_ROWS = 5, GRID_COLS = 6, CELL_WIDTH = 65, CELL_HEIGHT = 65;
        let START_STATE = { r: 2, c: 0 }, GOAL_STATE = { r: 0, c: 5 };
        let OBSTACLES = [ { r: 1, c: 1 },{ r: 1, c: 2 },{ r: 1, c: 3 },{ r: 3, c: 3 },{ r: 3, c: 4 }];
        const GOAL_REWARD = 10, OBSTACLE_PENALTY = -10, STEP_REWARD = -0.1;
        
        let IS_STOCHASTIC_ENV = false;
        let PROB_INTENDED = 0.8, PROB_SLIP_LEFT = 0.1, PROB_SLIP_RIGHT = 0.1;

        const ACTIONS = {
            UP:    { dr: -1, dc:  0, symbol: '‚Üë', key: 'UP' },
            DOWN:  { dr:  1, dc:  0, symbol: '‚Üì', key: 'DOWN' },
            LEFT:  { dr:  0, dc: -1, symbol: '‚Üê', key: 'LEFT' },
            RIGHT: { dr:  0, dc:  1, symbol: '‚Üí', key: 'RIGHT' }
        };
        const ACTION_KEYS = Object.keys(ACTIONS); // ['UP', 'DOWN', 'LEFT', 'RIGHT']
        const ACTION_ORDER = [ACTIONS.UP, ACTIONS.DOWN, ACTIONS.LEFT, ACTIONS.RIGHT]; // Consistent order for slips

        let GAMMA = 0.9, THETA = 0.0001, animationSpeed = 500;
        let ALPHA = 0.5, EPSILON = 0.1, EPISODES = 50;
        let currentAlgorithm = "valueIteration"; // "valueIteration" or "policyIteration"

        // DOM Elements (get them all once)
        const ui = {
            gridContainer: document.getElementById('grid-container'),
            startAlgorithmButton: document.getElementById('start-algorithm'),
            animateAgentButton: document.getElementById('animate-agent'),
            resetGridButton: document.getElementById('reset-grid'),
            gammaInput: document.getElementById('gamma-input'),
            speedInput: document.getElementById('speed-input'),
            statusMessage: document.getElementById('status-message'),
            algorithmNameDisplay: document.getElementById('algorithm-name'),
            iterationCountDisplay: document.getElementById('iteration-count'),
            deltaValueDisplay: document.getElementById('delta-value'),
            stepCountDisplay: document.getElementById('step-count'),
            scenarioSelect: document.getElementById('scenario-select'),
            configRowsInput: document.getElementById('config-rows'),
            configColsInput: document.getElementById('config-cols'),
            configStartInput: document.getElementById('config-start'),
            configGoalInput: document.getElementById('config-goal'),
            configObstaclesInput: document.getElementById('config-obstacles'),
            stochasticEnvSelect: document.getElementById('stochastic-env'),
            probIntendedInput: document.getElementById('prob-intended'),
            probSlipInput: document.getElementById('prob-slip'),
            applyConfigButton: document.getElementById('apply-config'),
            algorithmSelect: document.getElementById('algorithm-select'),
            alphaInput: document.getElementById('alpha-input'),
            epsilonInput: document.getElementById('epsilon-input'),
            episodesInput: document.getElementById('episodes-input'),
        };

        let V = [], policy = [], Q_VALUES = [];
        let agentElement = null, currentAgentPos = { ...START_STATE };
        let algorithmInterval = null, agentAnimationInterval = null;
        let currentIteration = 0, currentSteps = 0;
        let minV = 0, maxV = 0; // For heatmap

        const PREDEFINED_SCENARIOS = [ /* ... (same as before) ... */
             { name: "Standard", rows: 5, cols: 6, start: { r: 2, c: 0 }, goal: { r: 0, c: 5 }, obstacles: [ { r: 1, c: 1 }, { r: 1, c: 2 }, { r: 1, c: 3 }, { r: 3, c: 3 }, { r: 3, c: 4 }]},
             { name: "Leeres Feld", rows: 4, cols: 5, start: { r: 3, c: 0 }, goal: { r: 0, c: 4 }, obstacles: []},
             { name: "Einfaches Labyrinth", rows: 7, cols: 7, start: { r: 6, c: 0 }, goal: { r: 0, c: 6 }, obstacles: [ { r: 1, c: 1 }, { r: 1, c: 2 }, { r: 1, c: 3 }, { r: 1, c: 4 }, { r: 1, c: 5 }, { r: 3, c: 1 }, { r: 3, c: 2 }, { r: 3, c: 3 }, { r: 3, c: 4 }, { r: 3, c: 5 }, { r: 5, c: 1 }, { r: 5, c: 2 }, { r: 5, c: 3 }, { r: 5, c: 4 }, { r: 5, c: 5 } ]},
             { name: "Engpass", rows: 5, cols: 7, start: { r: 2, c: 0 }, goal: { r: 2, c: 6 }, obstacles: [ { r: 0, c: 3 }, { r: 1, c: 3 }, { r: 3, c: 3 }, { r: 4, c: 3 } ]}
        ];

        // --- INITIALIZATION & CONFIG ---
        function populateConfigUIWithCurrentGlobals() { /* ... (same as before) ... */
            ui.configRowsInput.value = GRID_ROWS; ui.configColsInput.value = GRID_COLS;
            ui.configStartInput.value = `${START_STATE.r},${START_STATE.c}`; ui.configGoalInput.value = `${GOAL_STATE.r},${GOAL_STATE.c}`;
            ui.configObstaclesInput.value = OBSTACLES.map(obs => `${obs.r},${obs.c}`).join('\n');
            ui.stochasticEnvSelect.value = IS_STOCHASTIC_ENV ? "1" : "0";
            ui.probIntendedInput.value = PROB_INTENDED; ui.probSlipInput.value = PROB_SLIP_LEFT; // Assuming symmetric slip
        }
        function loadScenario(scenario) { /* ... (same as before, ensure IS_STOCHASTIC_ENV etc. are part of scenario or reset) ... */
            GRID_ROWS = scenario.rows; GRID_COLS = scenario.cols;
            START_STATE = { ...scenario.start }; GOAL_STATE = { ...scenario.goal };
            OBSTACLES = scenario.obstacles.map(obs => ({ ...obs }));
            IS_STOCHASTIC_ENV = scenario.is_stochastic !== undefined ? scenario.is_stochastic : false; // Default to deterministic
            PROB_INTENDED = scenario.prob_intended !== undefined ? scenario.prob_intended : 0.8;
            PROB_SLIP_LEFT = scenario.prob_slip !== undefined ? scenario.prob_slip / 2 : 0.1; // Example: divide slip for L/R
            PROB_SLIP_RIGHT = scenario.prob_slip !== undefined ? scenario.prob_slip / 2 : 0.1;
            populateConfigUIWithCurrentGlobals();
            applyConfiguration(false);
            updateStatus(`Szenario "${scenario.name}" geladen.`, "info");
        }
        function populateScenarioDropdown() { /* ... (same as before) ... */
            PREDEFINED_SCENARIOS.forEach((scenario, index) => {
                const option = document.createElement('option'); option.value = index; option.textContent = scenario.name;
                ui.scenarioSelect.appendChild(option);
            });
            ui.scenarioSelect.addEventListener('change', (e) => {
                loadScenario(PREDEFINED_SCENARIOS[parseInt(e.target.value)]);
            });
        }
        function parseCoordinateString(str, maxR, maxC) { /* ... (use r,c consistently) ... */
            const parts = str.split(','); if (parts.length !== 2) return null;
            const r = parseInt(parts[0].trim()), c = parseInt(parts[1].trim());
            if (isNaN(r) || isNaN(c) || r < 0 || r >= maxR || c < 0 || c >= maxC) return null;
            return { r, c };
        }
        function applyConfiguration(showAlerts = true) { /* ... (update to use r,c, handle new prob inputs) ... */
            if (algorithmInterval) clearInterval(algorithmInterval);
            if (agentAnimationInterval) clearInterval(agentAnimationInterval);

            const newRows = parseInt(ui.configRowsInput.value), newCols = parseInt(ui.configColsInput.value);
            if (isNaN(newRows) || newRows < 2 || newRows > 15 || isNaN(newCols) || newCols < 2 || newCols > 15) { // Max 15 for perf
                if(showAlerts) updateStatus("Grid Gr√∂√üe: 2-15 Zeilen/Spalten.", "error"); return;
            }
            const newStart = parseCoordinateString(ui.configStartInput.value, newRows, newCols);
            if (!newStart) { if(showAlerts) updateStatus("Ung√ºltiges Startformat.", "error"); return; }
            const newGoal = parseCoordinateString(ui.configGoalInput.value, newRows, newCols);
            if (!newGoal) { if(showAlerts) updateStatus("Ung√ºltiges Zielformat.", "error"); return; }
            if (newStart.r === newGoal.r && newStart.c === newGoal.c) { if(showAlerts) updateStatus("Start/Ziel nicht identisch.", "error"); return; }

            const newObstacles = [];
            ui.configObstaclesInput.value.split('\n').forEach(line => {
                if (line.trim() === "") return;
                const obs = parseCoordinateString(line, newRows, newCols);
                if (!obs) { if(showAlerts) updateStatus(`Ung√ºltiges Hindernis: "${line}".`, "error"); throw new Error("Bad obstacle"); }
                newObstacles.push(obs);
            });
            if (newObstacles.some(o => o.r === newStart.r && o.c === newStart.c)) { if(showAlerts) updateStatus("Start ist Hindernis.", "error"); return; }
            if (newObstacles.some(o => o.r === newGoal.r && o.c === newGoal.c)) { if(showAlerts) updateStatus("Ziel ist Hindernis.", "error"); return; }

            GRID_ROWS = newRows; GRID_COLS = newCols; START_STATE = newStart; GOAL_STATE = newGoal; OBSTACLES = newObstacles;
            currentAgentPos = { ...START_STATE };
            IS_STOCHASTIC_ENV = ui.stochasticEnvSelect.value === "1";
            PROB_INTENDED = parseFloat(ui.probIntendedInput.value);
            let slipVal = parseFloat(ui.probSlipInput.value); // This is per side
            PROB_SLIP_LEFT = slipVal; PROB_SLIP_RIGHT = slipVal;
            // Ensure probabilities sum to 1 (or close enough) if intended is not 1
            if (PROB_INTENDED < 1) {
                let totalSlip = PROB_SLIP_LEFT + PROB_SLIP_RIGHT;
                if (PROB_INTENDED + totalSlip > 1.001) { // allow for small float errors
                    let overflow = (PROB_INTENDED + totalSlip) - 1.0;
                    PROB_INTENDED -= overflow; // Reduce intended first
                    if (PROB_INTENDED < 0) { // if intended becomes too small, adjust slips
                         PROB_INTENDED = 0;
                         let remainingProb = 1.0;
                         PROB_SLIP_LEFT = remainingProb /2;
                         PROB_SLIP_RIGHT = remainingProb /2;
                    }
                    updateStatus("Wahrscheinlichkeiten > 1, P(Beabsichtigt) angepasst.", "warning");
                    ui.probIntendedInput.value = PROB_INTENDED.toFixed(2);
                } else if (PROB_INTENDED + totalSlip < 0.999) {
                    PROB_INTENDED = 1.0 - totalSlip; // Increase intended if sum is less than 1
                     updateStatus("Wahrscheinlichkeiten < 1, P(Beabsichtigt) angepasst.", "warning");
                    ui.probIntendedInput.value = PROB_INTENDED.toFixed(2);
                }

            } else { // Deterministic if PROB_INTENDED is 1
                PROB_SLIP_LEFT = 0; PROB_SLIP_RIGHT = 0;
            }
            
            if(showAlerts) updateStatus("Konfiguration angewendet.", "info");
            initializeGrid();
        }

        function initializeGrid() { /* ... (Add Q_VALUES init, cell click handler modification for Q-display) ... */
            ui.gridContainer.innerHTML = '';
            ui.gridContainer.style.gridTemplateRows = `repeat(${GRID_ROWS}, ${CELL_HEIGHT}px)`;
            ui.gridContainer.style.gridTemplateColumns = `repeat(${GRID_COLS}, ${CELL_WIDTH}px)`;

            V = Array(GRID_ROWS).fill(null).map(() => Array(GRID_COLS).fill(0));
            policy = Array(GRID_ROWS).fill(null).map(() => Array(GRID_COLS).fill(null));
            Q_VALUES = Array(GRID_ROWS).fill(null).map(() => 
                Array(GRID_COLS).fill(null).map(() => ({ UP: 0, DOWN: 0, LEFT: 0, RIGHT: 0 }))
            );
            currentAgentPos = { ...START_STATE };

            for (let r = 0; r < GRID_ROWS; r++) {
                for (let c = 0; c < GRID_COLS; c++) {
                    const cell = document.createElement('div');
                    cell.classList.add('grid-cell');
                    cell.style.width = `${CELL_WIDTH}px`; cell.style.height = `${CELL_HEIGHT}px`;
                    cell.dataset.r = r; cell.dataset.c = c;

                    // V-Value Text (now centered on top of Qs)
                    const vText = document.createElement('span'); 
                    vText.classList.add('value-text'); 
                    cell.appendChild(vText);

                    // Q-Values Container
                    const qContainer = document.createElement('div');
                    qContainer.classList.add('q-values-container');
                    ACTION_KEYS.forEach(key => {
                        const qSpan = document.createElement('span');
                        qSpan.classList.add('q-value', `q-${key.toLowerCase()}`);
                        qSpan.textContent = '0.0';
                        qContainer.appendChild(qSpan);
                    });
                    cell.appendChild(qContainer);
                    
                    const pArrow = document.createElement('span'); 
                    pArrow.classList.add('policy-arrow'); 
                    cell.appendChild(pArrow);
                    
                    cell.addEventListener('click', () => handleCellClick(r, c));
                    if (!isStart(r,c) && !isGoal(r,c)) cell.classList.add('interactive-obstacle');

                    if (isStart(r,c)) cell.classList.add('start');
                    else if (isGoal(r,c)) cell.classList.add('goal');
                    else if (isObstacle({r,c})) cell.classList.add('obstacle'); // Pass object to isObstacle
                    
                    ui.gridContainer.appendChild(cell);
                }
            }
            if (agentElement) { agentElement.remove(); agentElement = null; }
            placeAgent(START_STATE.r, START_STATE.c);
            updateGridDisplay();
            resetStats();
            setControlsDisabled(false);
            ui.animateAgentButton.disabled = true; 
            if (!ui.statusMessage.textContent.includes("Konfiguration angewendet") && !ui.statusMessage.textContent.includes("Szenario geladen")) {
                 updateStatus('Grid initialisiert. Klicke auf Zellen f√ºr Hindernisse.');
            }
        }
        function handleCellClick(r, c) { /* ... (same as before, ensure r, c are used) ... */
            if (algorithmInterval || agentAnimationInterval) { updateStatus("Bitte Algorithmus/Animation stoppen.", "error"); return; }
            if ((r === START_STATE.r && c === START_STATE.c) || (r === GOAL_STATE.r && c === GOAL_STATE.c)) { updateStatus("Start/Ziel nicht √§nderbar.", "error"); return; }
            const cell = ui.gridContainer.querySelector(`[data-r='${r}'][data-c='${c}']`);
            const obsIdx = OBSTACLES.findIndex(o => o.r === r && o.c === c);
            if (obsIdx > -1) {
                OBSTACLES.splice(obsIdx, 1); cell.classList.remove('obstacle');
                const { bgColor } = getHeatmapColorAndRange(V[r][c], minV, maxV); cell.style.backgroundColor = bgColor;
            } else {
                OBSTACLES.push({ r, c }); cell.classList.add('obstacle'); cell.style.backgroundColor = '';
            }
            populateConfigUIWithCurrentGlobals(); 
            updateStatus(`Hindernis bei (${r},${c}) ${obsIdx > -1 ? 'entfernt' : 'gesetzt'}.`);
        }

        // --- MDP UTILITIES (Position, Rewards, Stochasticity) ---
        function isObstacle(pos) { return OBSTACLES.some(o => o.r === pos.r && o.c === pos.c); }
        function isGoal(pos) { return GOAL_STATE && pos.r === GOAL_STATE.r && pos.c === GOAL_STATE.c; }
        function isStart(pos) { return START_STATE && pos.r === START_STATE.r && pos.c === START_STATE.c; }
        function isValidPosition(pos) { return pos.r >= 0 && pos.r < GRID_ROWS && pos.c >= 0 && pos.c < GRID_COLS; }
        
        function getActualActionOutcomes(intendedActionKey) {
            if (!IS_STOCHASTIC_ENV || PROB_INTENDED >= 1.0) {
                return [{ action: ACTIONS[intendedActionKey], prob: 1.0 }];
            }

            const outcomes = [];
            outcomes.push({ action: ACTIONS[intendedActionKey], prob: PROB_INTENDED });

            const intendedActionIndex = ACTION_ORDER.findIndex(a => a.key === intendedActionKey);
            const leftSlipAction = ACTION_ORDER[(intendedActionIndex + ACTION_ORDER.length - 1) % ACTION_ORDER.length];
            const rightSlipAction = ACTION_ORDER[(intendedActionIndex + 1) % ACTION_ORDER.length];

            if (PROB_SLIP_LEFT > 0) outcomes.push({ action: leftSlipAction, prob: PROB_SLIP_LEFT });
            if (PROB_SLIP_RIGHT > 0) outcomes.push({ action: rightSlipAction, prob: PROB_SLIP_RIGHT });
            
            // Normalize probabilities if they don't sum to 1 due to configuration
            const totalProb = outcomes.reduce((sum, o) => sum + o.prob, 0);
            if (Math.abs(totalProb - 1.0) > 0.001 && totalProb > 0) { // Check if not close to 1 and not 0
                outcomes.forEach(o => o.prob /= totalProb);
            }
            return outcomes;
        }

        function calculateQValue(r, c, intendedActionKey) {
            let expectedQValue = 0;
            const possibleOutcomes = getActualActionOutcomes(intendedActionKey);

            for (const outcome of possibleOutcomes) {
                const actualAction = outcome.action;
                const prob = outcome.prob;
                let next_r = r + actualAction.dr;
                let next_c = c + actualAction.dc;
                let reward = STEP_REWARD;
                let next_v;

                if (!isValidPosition({r: next_r, c: next_c})) { // Hit wall
                    next_r = r; // Stay in place
                    next_c = c;
                    // reward remains STEP_REWARD (or a specific wall penalty if desired)
                    next_v = V[r][c];
                } else if (isObstacle({r: next_r, c: next_c})) {
                    // Hit obstacle - different models possible.
                    // Model 1: Bounce back (or stay) and get penalty.
                    next_r = r; // Stay in place
                    next_c = c;
                    reward = OBSTACLE_PENALTY; // Penalty for *attempting* to move into obstacle
                    next_v = V[r][c];
                } else if (isGoal({r: next_r, c: next_c})) {
                    reward = GOAL_REWARD;
                    next_v = V[next_r][next_c]; // Which is GOAL_REWARD if goal V is fixed
                } else {
                    // Standard move
                    next_v = V[next_r][next_c];
                }
                expectedQValue += prob * (reward + GAMMA * next_v);
            }
            return expectedQValue;
        }

        function sampleTransition(r, c, intendedActionKey) {
            let actionKey = intendedActionKey;
            if (IS_STOCHASTIC_ENV && PROB_INTENDED < 1.0) {
                const outcomes = getActualActionOutcomes(intendedActionKey);
                let rand = Math.random();
                let cumulative = 0;
                for (const o of outcomes) {
                    cumulative += o.prob;
                    if (rand <= cumulative) { actionKey = o.action.key; break; }
                }
            }
            let next_r = r + ACTIONS[actionKey].dr;
            let next_c = c + ACTIONS[actionKey].dc;
            let reward = STEP_REWARD;
            if (!isValidPosition({r: next_r, c: next_c})) {
                next_r = r; next_c = c;
            } else if (isObstacle({r: next_r, c: next_c})) {
                next_r = r; next_c = c; reward = OBSTACLE_PENALTY;
            } else if (isGoal({r: next_r, c: next_c})) {
                reward = GOAL_REWARD;
            }
            return { next_r, next_c, reward };
        }
        
        // --- DISPLAY ---
        function getHeatmapColorAndRange(value, currentMin, currentMax) { /* ... (same as before) ... */
            let newMinV = Infinity, newMaxV = -Infinity, hasValid = false;
            for (let r_idx = 0; r_idx < GRID_ROWS; r_idx++) for (let c_idx = 0; c_idx < GRID_COLS; c_idx++) {
                if (!isObstacle({r:r_idx,c:c_idx}) && !isGoal({r:r_idx,c:c_idx}) && !isStart({r:r_idx,c:c_idx})) {
                    newMinV = Math.min(newMinV, V[r_idx][c_idx]); newMaxV = Math.max(newMaxV, V[r_idx][c_idx]); hasValid = true;
                }
            }
            if (!hasValid || newMinV === Infinity) { newMinV = 0; newMaxV = 0; }
            if (newMinV === newMaxV && hasValid) { newMaxV = newMinV + 0.01; } // Ensure some range
            minV = newMinV; maxV = newMaxV; // Update global min/max for reference

            let normVal = 0;
            if (maxV > minV) normVal = (value - minV) / (maxV - minV);
            else if (value >= minV) normVal = 1;
            normVal = Math.max(0, Math.min(1, normVal));
            const hue = 180 + (120 - 180) * normVal, sat = 65, light = 90 - (30 * normVal);
            return { bgColor: `hsl(${hue}, ${sat}%, ${light}%)`};
        }

        function updateGridDisplay() { /* ... (Update to show Q-values from Q_VALUES array) ... */
            // Update global minV, maxV first for consistent heatmap coloring
            let currentMin = Infinity, currentMax = -Infinity, found = false;
            for(let r_idx=0; r_idx<GRID_ROWS; ++r_idx) for(let c_idx=0; c_idx<GRID_COLS; ++c_idx) {
                if(!isObstacle({r:r_idx,c:c_idx}) && !isGoal({r:r_idx,c:c_idx}) && !isStart({r:r_idx,c:c_idx})) {
                    currentMin = Math.min(currentMin, V[r_idx][c_idx]); currentMax = Math.max(currentMax, V[r_idx][c_idx]); found = true;
                }
            }
            minV = found ? currentMin : 0; maxV = found ? (currentMin === currentMax ? currentMin + 0.01 : currentMax) : 0.01;


            for (let r = 0; r < GRID_ROWS; r++) {
                for (let c = 0; c < GRID_COLS; c++) {
                    const cell = ui.gridContainer.querySelector(`[data-r='${r}'][data-c='${c}']`);
                    if (!cell) continue;
                    cell.querySelector('.value-text').textContent = V[r][c].toFixed(2);
                    const pArrow = cell.querySelector('.policy-arrow');
                    pArrow.textContent = policy[r][c] ? ACTIONS[policy[r][c]].symbol : '';
                    if (isGoal({r,c}) || isObstacle({r,c})) pArrow.style.opacity = '0.3'; else pArrow.style.opacity = '1';

                    if (!cell.classList.contains('start') && !cell.classList.contains('goal') && !cell.classList.contains('obstacle')) {
                        const { bgColor } = getHeatmapColorAndRange(V[r][c], minV, maxV); // Use global minV, maxV
                        cell.style.backgroundColor = bgColor;
                    } else {
                        cell.style.backgroundColor = ''; // Let CSS classes handle it
                    }

                    // Display Q-Values
                    const qContainer = cell.querySelector('.q-values-container');
                    if (qContainer && Q_VALUES[r] && Q_VALUES[r][c] && !(isGoal({r,c}) || isObstacle({r,c}))) {
                        ACTION_KEYS.forEach(key => {
                            const qSpan = qContainer.querySelector(`.q-${key.toLowerCase()}`);
                            if (qSpan) qSpan.textContent = Q_VALUES[r][c][key].toFixed(1);
                        });
                    } else if (qContainer) { // Hide Qs for goal/obstacle
                         ACTION_KEYS.forEach(key => {
                            const qSpan = qContainer.querySelector(`.q-${key.toLowerCase()}`);
                            if (qSpan) qSpan.textContent = '';
                        });
                    }
                }
            }
        }
        function placeAgent(r, c) { /* ... (use r,c consistently) ... */
            if (!agentElement) {
                agentElement = document.createElement('div'); agentElement.classList.add('agent');
                ui.gridContainer.appendChild(agentElement);
            }
            currentAgentPos = { r, c };
            const agentSizeStyle = window.getComputedStyle(agentElement);
            const agentW = parseFloat(agentSizeStyle.width), agentH = parseFloat(agentSizeStyle.height);
            const offX = c * CELL_WIDTH + (CELL_WIDTH - agentW) / 2, offY = r * CELL_HEIGHT + (CELL_HEIGHT - agentH) / 2;
            agentElement.style.transform = `translate(${offX}px, ${offY}px)`;
        }
        
        // --- ALGORITHMS ---
        // Value Iteration
        function performValueIterationStep() { /* ... (Update to store Q-values in Q_VALUES global) ... */
            let delta = 0;
            const newV = V.map(rowArr => [...rowArr]);
            for (let r = 0; r < GRID_ROWS; r++) {
                for (let c = 0; c < GRID_COLS; c++) {
                    if (isObstacle({r,c})) { newV[r][c] = 0; ACTION_KEYS.forEach(k => Q_VALUES[r][c][k] = 0); continue; }
                    if (isGoal({r,c})) { newV[r][c] = GOAL_REWARD; ACTION_KEYS.forEach(k => Q_VALUES[r][c][k] = GOAL_REWARD); continue; }
                    
                    const oldV_s = V[r][c];
                    let maxQ_s = -Infinity;
                    ACTION_KEYS.forEach(actionKey => {
                        const q_sa = calculateQValue(r, c, actionKey);
                        Q_VALUES[r][c][actionKey] = q_sa; // Store Q-value
                        if (q_sa > maxQ_s) maxQ_s = q_sa;
                    });
                    newV[r][c] = maxQ_s;
                    delta = Math.max(delta, Math.abs(oldV_s - newV[r][c]));
                }
            }
            V = newV;
            return delta;
        }

        // Policy Iteration
        function performPolicyEvaluationStep(currentPolicy) {
            let delta = 0;
            const newV = V.map(rowArr => [...rowArr]);
            for (let r = 0; r < GRID_ROWS; r++) {
                for (let c = 0; c < GRID_COLS; c++) {
                    if (isObstacle({r,c})) { newV[r][c] = 0; continue; }
                    if (isGoal({r,c})) { newV[r][c] = GOAL_REWARD; continue; }

                    const oldV_s = V[r][c];
                    const actionKey = currentPolicy[r][c];
                    if (!actionKey) { // Should not happen if policy is complete for non-terminal
                        newV[r][c] = 0; // Default or some other value
                        continue;
                    }
                    // V_pi(s) = E[R + gamma * V_pi(s')] = Q_pi(s, pi(s))
                    // So, we calculate Q-value for the action specified by policy
                    newV[r][c] = calculateQValue(r, c, actionKey); 
                    ACTION_KEYS.forEach(ak => Q_VALUES[r][c][ak] = (ak === actionKey) ? newV[r][c] : -Infinity); // Show only Q for policy's action

                    delta = Math.max(delta, Math.abs(oldV_s - newV[r][c]));
                }
            }
            V = newV;
            return delta;
        }

        function performPolicyImprovement() { // Also updates global Q_VALUES
            let policyStable = true;
            const newPolicy = policy.map(rowArr => [...rowArr]);
            for (let r = 0; r < GRID_ROWS; r++) {
                for (let c = 0; c < GRID_COLS; c++) {
                    if (isObstacle({r,c}) || isGoal({r,c})) { newPolicy[r][c] = null; continue; }
                    
                    const oldAction = policy[r][c];
                    let bestActionKey = null;
                    let maxQ_s = -Infinity;

                    ACTION_KEYS.forEach(actionKey => {
                        const q_sa = calculateQValue(r, c, actionKey);
                        Q_VALUES[r][c][actionKey] = q_sa; // Store Q-value
                        if (q_sa > maxQ_s) {
                            maxQ_s = q_sa;
                            bestActionKey = actionKey;
                        }
                    });
                    newPolicy[r][c] = bestActionKey;
                    if (oldAction !== newPolicy[r][c]) policyStable = false;
                }
            }
            policy = newPolicy;
            return policyStable;
        }
        
        function extractOptimalPolicyFromQ() { // Used by VI after Qs are computed
             for (let r = 0; r < GRID_ROWS; r++) {
                for (let c = 0; c < GRID_COLS; c++) {
                    if (isObstacle({r,c}) || isGoal({r,c})) { policy[r][c] = null; continue; }
                    let bestActionKey = null;
                    let maxQ = -Infinity;
                    ACTION_KEYS.forEach(key => {
                        if (Q_VALUES[r][c][key] > maxQ) {
                            maxQ = Q_VALUES[r][c][key];
                            bestActionKey = key;
                        }
                    });
                    policy[r][c] = bestActionKey;
                }
            }
        }


        function startSelectedAlgorithm() {
            currentAlgorithm = ui.algorithmSelect.value;
            ui.algorithmNameDisplay.textContent =
                currentAlgorithm === "valueIteration" ? "Value Iteration" :
                (currentAlgorithm === "policyIteration" ? "Policy Iteration" : "Q-Learning");
            GAMMA = parseFloat(ui.gammaInput.value);
            animationSpeed = parseInt(ui.speedInput.value);
            if (GAMMA < 0 || GAMMA > 1) { updateStatus('Ung√ºltiges Gamma!', 'error'); return; }

            setControlsDisabled(true);
            ui.animateAgentButton.disabled = true;
            updateStatus(`${ui.algorithmNameDisplay.textContent} gestartet...`);
            currentIteration = 0;
            placeAgent(START_STATE.r, START_STATE.c); 
            currentSteps = 0; ui.stepCountDisplay.textContent = currentSteps;

            if (currentAlgorithm === "valueIteration") {
                algorithmInterval = setInterval(() => {
                    const iterDelta = performValueIterationStep(); // This now also updates Q_VALUES
                    extractOptimalPolicyFromQ(); // Policy from Q_VALUES
                    currentIteration++;
                    updateGridDisplay(); 
                    updateStats(currentIteration, iterDelta, currentSteps);
                    ui.animateAgentButton.disabled = !policy[START_STATE.r]?.[START_STATE.c];

                    if (iterDelta < THETA || currentIteration > GRID_ROWS * GRID_COLS * 25) { // Max iter guard
                        clearInterval(algorithmInterval); algorithmInterval = null;
                        updateStatus(`VI Konvergiert: ${currentIteration} Iter., Delta: ${iterDelta.toFixed(5)}`);
                        setControlsDisabled(false);
                        ui.animateAgentButton.disabled = !policy[START_STATE.r]?.[START_STATE.c];
                        updateStats(currentIteration, iterDelta, currentSteps);
                    } else {
                        updateStatus(`VI Iter. ${currentIteration}, Delta: ${iterDelta.toFixed(4)}`);
                    }
                }, Math.max(5, animationSpeed / 10));
            } else if (currentAlgorithm === "policyIteration") { // Policy Iteration
                // Initialize V and policy somewhat if needed (e.g., V to 0, policy to random/first action)
                V = Array(GRID_ROWS).fill(null).map(() => Array(GRID_COLS).fill(0));
                policy = Array(GRID_ROWS).fill(null).map(row => Array(GRID_COLS).fill(null).map((_,c_idx) => {
                     // Initial arbitrary policy for non-terminal states
                    for(let r_idx=0; r_idx<GRID_ROWS; ++r_idx) {
                        for(let c_idx_p=0; c_idx_p<GRID_COLS; ++c_idx_p) {
                             if (!isObstacle({r:r_idx,c:c_idx_p}) && !isGoal({r:r_idx,c:c_idx_p})) policy[r_idx][c_idx_p] = ACTION_KEYS[0];
                        }
                    }
                }));
                updateGridDisplay(); // Show initial V=0 and arbitrary policy

                let policyStable = false;
                algorithmInterval = setInterval(() => {
                    currentIteration++; // Counts full Policy Eval + Policy Improv as one iteration
                    // 1. Policy Evaluation
                    let evalIteration = 0;
                    let evalDelta;
                    // TODO: Potentially animate policy evaluation steps as sub-iterations
                    // For now, run policy evaluation to convergence for simplicity in animation
                    do {
                        evalDelta = performPolicyEvaluationStep(policy); // This updates V and Q_VALUES (for current policy action)
                        evalIteration++;
                        // updateGridDisplay(); // Optional: show V updating during evaluation
                    } while (evalDelta >= THETA && evalIteration < GRID_ROWS * GRID_COLS * 10); // Max eval iterations
                    
                    // 2. Policy Improvement
                    policyStable = performPolicyImprovement(); // This updates policy and Q_VALUES (for all actions)
                    
                    updateGridDisplay(); // Show new V and new Policy, and new Qs
                    const statusText = policyStable ? "Policy Stabil!" : `Policy nicht stabil`;
                    updateStats(currentIteration, statusText, currentSteps); // Delta for PI is just status
                    ui.animateAgentButton.disabled = !policy[START_STATE.r]?.[START_STATE.c];
                    
                    if (policyStable || currentIteration > GRID_ROWS * GRID_COLS * 5) { // Max PI iterations
                        clearInterval(algorithmInterval); algorithmInterval = null;
                        updateStatus(`PI Konvergiert: ${currentIteration} Iter. ${statusText}`);
                        setControlsDisabled(false);
                        ui.animateAgentButton.disabled = !policy[START_STATE.r]?.[START_STATE.c];
                    } else {
                         updateStatus(`PI Iter. ${currentIteration}. Eval in ${evalIteration} Schritten. ${statusText}`);
                    }
                }, Math.max(200, animationSpeed)); // PI steps are slower as eval is an inner loop
            } else { // Q-Learning
                V = Array(GRID_ROWS).fill(null).map(() => Array(GRID_COLS).fill(0));
                policy = Array(GRID_ROWS).fill(null).map(() => Array(GRID_COLS).fill(null));
                Q_VALUES = Array(GRID_ROWS).fill(null).map(() => Array(GRID_COLS).fill(null).map(() => ({UP:0,DOWN:0,LEFT:0,RIGHT:0})));
                updateGridDisplay();
                let episode = 0;
                let stepInEpisode = 0;
                placeAgent(START_STATE.r, START_STATE.c);
                algorithmInterval = setInterval(() => {
                    const state = { ...currentAgentPos };
                    let actionKey;
                    if (Math.random() < EPSILON || !policy[state.r][state.c]) {
                        actionKey = ACTION_KEYS[Math.floor(Math.random() * ACTION_KEYS.length)];
                    } else {
                        actionKey = policy[state.r][state.c];
                    }
                    const { next_r, next_c, reward } = sampleTransition(state.r, state.c, actionKey);
                    const maxNextQ = Math.max(...ACTION_KEYS.map(k => Q_VALUES[next_r][next_c][k]));
                    const oldQ = Q_VALUES[state.r][state.c][actionKey];
                    Q_VALUES[state.r][state.c][actionKey] = oldQ + ALPHA * (reward + GAMMA * maxNextQ - oldQ);
                    V[state.r][state.c] = Math.max(...ACTION_KEYS.map(k => Q_VALUES[state.r][state.c][k]));
                    policy[state.r][state.c] = ACTION_KEYS.reduce((best, k) => Q_VALUES[state.r][state.c][k] > Q_VALUES[state.r][state.c][best] ? k : best, ACTION_KEYS[0]);
                    placeAgent(next_r, next_c);
                    stepInEpisode++;
                    currentSteps++;
                    updateGridDisplay();
                    updateStats(episode + 1, `Step ${stepInEpisode}`, currentSteps);

                    if (isGoal({ r: next_r, c: next_c }) || stepInEpisode > GRID_ROWS * GRID_COLS * 3) {
                        episode++;
                        stepInEpisode = 0;
                        placeAgent(START_STATE.r, START_STATE.c);
                    }
                    if (episode >= EPISODES) {
                        clearInterval(algorithmInterval);
                        algorithmInterval = null;
                        updateStatus(`Q-Learning abgeschlossen nach ${episode} Episoden.`);
                        setControlsDisabled(false);
                        ui.animateAgentButton.disabled = !policy[START_STATE.r]?.[START_STATE.c];
                    }
                }, Math.max(5, animationSpeed / 10));
            }
        }
        
        function startAgentAnimation() { /* ... (largely same, use r,c for positions) ... */
            placeAgent(START_STATE.r, START_STATE.c);
            currentSteps = 0; setControlsDisabled(true); ui.animateAgentButton.disabled = true;
            updateStatus('Agent folgt Policy...');
            const maxAnimSteps = GRID_ROWS * GRID_COLS * 3; const visited = new Set();
            agentAnimationInterval = setInterval(() => {
                const stateKey = `${currentAgentPos.r},${currentAgentPos.c}`;
                if (isGoal(currentAgentPos)) { clearInterval(agentAnimationInterval); agentAnimationInterval=null; updateStatus(`üéâ Ziel: ${currentSteps} Schritte!`); setControlsDisabled(false); ui.animateAgentButton.disabled = !policy[START_STATE.r]?.[START_STATE.c]; return; }
                if (visited.has(stateKey) && visited.size > 1) { clearInterval(agentAnimationInterval); agentAnimationInterval=null; updateStatus(`‚ö†Ô∏è Agent im Kreis (Schritt ${currentSteps}).`); setControlsDisabled(false); ui.animateAgentButton.disabled = !policy[START_STATE.r]?.[START_STATE.c]; return; }
                visited.add(stateKey);
                if (currentSteps >= maxAnimSteps) { clearInterval(agentAnimationInterval); agentAnimationInterval=null; updateStatus(`‚ö†Ô∏è Max Schritte (${maxAnimSteps}) erreicht.`); setControlsDisabled(false); ui.animateAgentButton.disabled = !policy[START_STATE.r]?.[START_STATE.c]; return; }
                const actionKey = policy[currentAgentPos.r]?.[currentAgentPos.c];
                if (!actionKey) { clearInterval(agentAnimationInterval); agentAnimationInterval=null; updateStatus(`‚ùå Keine Aktion f√ºr (${currentAgentPos.r},${currentAgentPos.c}).`); setControlsDisabled(false); ui.animateAgentButton.disabled = !policy[START_STATE.r]?.[START_STATE.c]; return; }
                const action = ACTIONS[actionKey];
                const next_r = currentAgentPos.r + action.dr, next_c = currentAgentPos.c + action.dc;
                if (isValidPosition({r:next_r,c:next_c}) && !isObstacle({r:next_r,c:next_c})) {
                    placeAgent(next_r, next_c); currentSteps++;
                    updateStats(currentIteration, ui.deltaValueDisplay.textContent, currentSteps); // Keep delta from last algo run
                } else { clearInterval(agentAnimationInterval); agentAnimationInterval=null; updateStatus(`‚ùì Agent ung√ºltiger Zug (${currentAgentPos.r},${currentAgentPos.c}) mit ${actionKey}.`); setControlsDisabled(false); ui.animateAgentButton.disabled = !policy[START_STATE.r]?.[START_STATE.c]; }
            }, animationSpeed);
        }
        function resetGridWithCurrentConfig() { /* ... (use r,c, ensure Q_VALUES is reset) ... */
            if (algorithmInterval) clearInterval(algorithmInterval); if (agentAnimationInterval) clearInterval(agentAnimationInterval);
            algorithmInterval = null; agentAnimationInterval = null;
            V = Array(GRID_ROWS).fill(null).map(() => Array(GRID_COLS).fill(0));
            policy = Array(GRID_ROWS).fill(null).map(() => Array(GRID_COLS).fill(null));
            Q_VALUES = Array(GRID_ROWS).fill(null).map(() => Array(GRID_COLS).fill(null).map(() => ({ UP:0,DOWN:0,LEFT:0,RIGHT:0 })));
            currentAgentPos = { ...START_STATE };
            for (let r_idx=0; r_idx<GRID_ROWS; ++r_idx) for (let c_idx=0; c_idx<GRID_COLS; ++c_idx) {
                const cell = ui.gridContainer.querySelector(`[data-r='${r_idx}'][data-c='${c_idx}']`); if(!cell) continue;
                cell.classList.remove('start','goal','obstacle');
                if(isStart({r:r_idx,c:c_idx})) cell.classList.add('start'); else if(isGoal({r:r_idx,c:c_idx})) cell.classList.add('goal'); else if(isObstacle({r:r_idx,c:c_idx})) cell.classList.add('obstacle');
            }
            placeAgent(START_STATE.r, START_STATE.c); updateGridDisplay(); resetStats();
            setControlsDisabled(false); ui.animateAgentButton.disabled = true;
            updateStatus('Grid mit aktueller Konfiguration zur√ºckgesetzt.');
        }
        function updateStatus(msg, type='info') { ui.statusMessage.textContent = msg; ui.statusMessage.style.color = type === 'error' ? '#dc2626' : (type === 'warning' ? '#eab308' : '#4f46e5'); ui.statusMessage.style.borderColor = type === 'error' ? '#dc2626' : (type === 'warning' ? '#eab308' : '#4f46e5'); }
        function resetStats() { currentIteration=0; currentSteps=0; updateStats(0, "0.000", 0); ui.algorithmNameDisplay.textContent = ui.algorithmSelect.options[ui.algorithmSelect.selectedIndex].text; }
        function updateStats(iter, deltaOrStatus, steps) { ui.iterationCountDisplay.textContent = iter; ui.deltaValueDisplay.textContent = (typeof deltaOrStatus === 'string') ? deltaOrStatus : (parseFloat(deltaOrStatus).toFixed(Math.max(3,THETA.toString().split('.')[1]?.length || 0))); ui.stepCountDisplay.textContent = steps; }

        // --- EVENT LISTENERS ---
        ui.applyConfigButton.addEventListener('click', () => applyConfiguration(true));
        ui.startAlgorithmButton.addEventListener('click', startSelectedAlgorithm);
        ui.animateAgentButton.addEventListener('click', startAgentAnimation);
        ui.resetGridButton.addEventListener('click', resetGridWithCurrentConfig); 
        ui.gammaInput.addEventListener('change', e => { const v=parseFloat(e.target.value); if(!isNaN(v)&&v>=0&&v<=1)GAMMA=v; else{e.target.value=GAMMA;updateStatus('Gamma: 0-1','error');}});
        ui.speedInput.addEventListener('change', e => animationSpeed = parseInt(e.target.value));
        ui.alphaInput.addEventListener('change', e => { const v=parseFloat(e.target.value); if(!isNaN(v)&&v>=0&&v<=1) ALPHA=v; else { e.target.value=ALPHA; updateStatus('Alpha: 0-1','error'); }});
        ui.epsilonInput.addEventListener('change', e => { const v=parseFloat(e.target.value); if(!isNaN(v)&&v>=0&&v<=1) EPSILON=v; else { e.target.value=EPSILON; updateStatus('Epsilon: 0-1','error'); }});
        ui.episodesInput.addEventListener('change', e => { const v=parseInt(e.target.value); if(!isNaN(v)&&v>0) EPISODES=v; else { e.target.value=EPISODES; updateStatus('Episoden >0','error'); }});
        ui.algorithmSelect.addEventListener('change', e => { currentAlgorithm = e.target.value; resetStats(); updateStatus(`Algorithmus auf ${ui.algorithmSelect.options[ui.algorithmSelect.selectedIndex].text} ge√§ndert.`); });
        ui.stochasticEnvSelect.addEventListener('change', e => { IS_STOCHASTIC_ENV = e.target.value === "1"; updateStatus(`Umgebung ist nun ${IS_STOCHASTIC_ENV ? 'stochastisch' : 'deterministisch'}.`); });
        [ui.probIntendedInput, ui.probSlipInput].forEach(input => input.addEventListener('change', () => {
            // Simple validation, more complex one in applyConfiguration
            let pInt = parseFloat(ui.probIntendedInput.value);
            let pSlip = parseFloat(ui.probSlipInput.value); // this is per side
            if (pInt + 2 * pSlip > 1.0) updateStatus("Warnung: Summe der Wahrscheinlichkeiten > 1. Wird bei 'Anwenden' korrigiert.", "warning");
            else if (pInt + 2*pSlip < 1.0 && pInt < 1.0) updateStatus("Warnung: Summe der Wahrscheinlichkeiten < 1. Wird bei 'Anwenden' korrigiert.", "warning");
        }));


        // --- INITIAL PAGE LOAD ---
        populateScenarioDropdown();
        loadScenario(PREDEFINED_SCENARIOS[0]); // Load default, which calls initializeGrid
        resetStats(); // Set initial algo name
    </script>
</body>
</html>
